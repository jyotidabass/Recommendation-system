{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Personalized Ranking pairwise loss:**  \n",
    "Maximises the prediction difference between a positive example and a randomly chosen negative example. Useful when only positive interactions are present and optimising ROC AUC is desired.\n",
    "\n",
    "**Weighted Approximate-Rank Pairwise loss**:  \n",
    "Maximises the rank of positive examples by repeatedly sampling negative examples until rank violating one is found. Useful when only positive interactions are present and optimising the top of the recommendation list (precision@k) is desired.WARP deals with (user, positive item, negative item) triplets. \n",
    "\n",
    "\n",
    "This procedure yields roughly the following algorithm:\n",
    "\n",
    "- For a given (user, positive item pair), sample a negative item at random from all the remaining items. Compute predictions for both items; if the negative item’s prediction exceeds that of the positive item plus a margin, perform a gradient update to rank the positive item higher and the negative item lower. If there is no rank violation, continue sampling negative items until a violation is found.\n",
    "\n",
    "- If you found a violating negative example at the first try, make a large gradient update: this indicates that a lot of negative items are ranked higher than positives items given the current state of the model, and the model must be updated by a large amount. If it took a lot of sampling to find a violating example, perform a small update: the model is likely close to the optimum and should be updated at a low rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amitkaps/miniconda3/lib/python3.5/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "#Get the data\n",
    "\n",
    "import numpy as np\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Movie lens dataset:**\n",
    "\n",
    "![](img/movielens.png)\n",
    "GroupLens Research has collected and made available rating data sets from the MovieLens web site (http://movielens.org). The data sets were collected over various periods of time, depending on the size of the set.\n",
    "\n",
    "http://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch movielens 100k dataset**\n",
    "\n",
    "The dataset contains 100,000 interactions from 1000 users on 1700 movies, and is exhaustively described\n",
    "#in its README http://files.grouplens.org/datasets/movielens/ml-100k-README.txt\n",
    "\n",
    "This data set consists of:\n",
    "- 100,000 ratings (1-5) from 943 users on 1682 movies. \n",
    "- Each user has rated at least 20 movies. \n",
    "- Simple demographic info for the users (age, gender, occupation, zip)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "movielens = fetch_movielens() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_labels ['Toy Story (1995)' 'GoldenEye (1995)' 'Four Rooms (1995)' ...,\n",
      " 'Sliding Doors (1998)' 'You So Crazy (1994)'\n",
      " 'Scream of Stone (Schrei aus Stein) (1991)']\n",
      "test   (0, 19)\t4\n",
      "  (0, 32)\t4\n",
      "  (0, 60)\t4\n",
      "  (0, 116)\t3\n",
      "  (0, 154)\t2\n",
      "  (0, 159)\t4\n",
      "  (0, 170)\t5\n",
      "  (0, 188)\t3\n",
      "  (0, 201)\t5\n",
      "  (0, 264)\t4\n",
      "  (1, 12)\t4\n",
      "  (1, 49)\t5\n",
      "  (1, 250)\t5\n",
      "  (1, 279)\t3\n",
      "  (1, 280)\t3\n",
      "  (1, 289)\t3\n",
      "  (1, 291)\t4\n",
      "  (1, 296)\t4\n",
      "  (1, 311)\t3\n",
      "  (1, 313)\t1\n",
      "  (2, 244)\t1\n",
      "  (2, 293)\t2\n",
      "  (2, 322)\t2\n",
      "  (2, 327)\t5\n",
      "  (2, 330)\t4\n",
      "  :\t:\n",
      "  (940, 180)\t5\n",
      "  (940, 256)\t4\n",
      "  (940, 257)\t4\n",
      "  (940, 474)\t4\n",
      "  (940, 992)\t4\n",
      "  (941, 116)\t4\n",
      "  (941, 199)\t4\n",
      "  (941, 260)\t4\n",
      "  (941, 322)\t3\n",
      "  (941, 422)\t5\n",
      "  (941, 426)\t5\n",
      "  (941, 486)\t4\n",
      "  (941, 583)\t4\n",
      "  (941, 603)\t4\n",
      "  (941, 614)\t3\n",
      "  (942, 10)\t4\n",
      "  (942, 57)\t4\n",
      "  (942, 110)\t4\n",
      "  (942, 185)\t5\n",
      "  (942, 214)\t5\n",
      "  (942, 231)\t4\n",
      "  (942, 355)\t4\n",
      "  (942, 569)\t1\n",
      "  (942, 807)\t4\n",
      "  (942, 1066)\t2\n",
      "train   (0, 0)\t5\n",
      "  (0, 1)\t3\n",
      "  (0, 2)\t4\n",
      "  (0, 3)\t3\n",
      "  (0, 4)\t3\n",
      "  (0, 5)\t5\n",
      "  (0, 6)\t4\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t5\n",
      "  (0, 9)\t3\n",
      "  (0, 10)\t2\n",
      "  (0, 11)\t5\n",
      "  (0, 12)\t5\n",
      "  (0, 13)\t5\n",
      "  (0, 14)\t5\n",
      "  (0, 15)\t5\n",
      "  (0, 16)\t3\n",
      "  (0, 17)\t4\n",
      "  (0, 18)\t5\n",
      "  (0, 20)\t1\n",
      "  (0, 21)\t4\n",
      "  (0, 22)\t4\n",
      "  (0, 23)\t3\n",
      "  (0, 24)\t4\n",
      "  (0, 25)\t3\n",
      "  :\t:\n",
      "  (942, 723)\t1\n",
      "  (942, 731)\t4\n",
      "  (942, 738)\t4\n",
      "  (942, 755)\t2\n",
      "  (942, 762)\t4\n",
      "  (942, 764)\t3\n",
      "  (942, 784)\t2\n",
      "  (942, 793)\t3\n",
      "  (942, 795)\t3\n",
      "  (942, 815)\t4\n",
      "  (942, 823)\t4\n",
      "  (942, 824)\t3\n",
      "  (942, 830)\t2\n",
      "  (942, 839)\t4\n",
      "  (942, 927)\t5\n",
      "  (942, 940)\t1\n",
      "  (942, 942)\t5\n",
      "  (942, 1010)\t2\n",
      "  (942, 1027)\t2\n",
      "  (942, 1043)\t3\n",
      "  (942, 1046)\t2\n",
      "  (942, 1073)\t4\n",
      "  (942, 1187)\t3\n",
      "  (942, 1227)\t3\n",
      "  (942, 1329)\t3\n",
      "item_feature_labels ['Toy Story (1995)' 'GoldenEye (1995)' 'Four Rooms (1995)' ...,\n",
      " 'Sliding Doors (1998)' 'You So Crazy (1994)'\n",
      " 'Scream of Stone (Schrei aus Stein) (1991)']\n",
      "item_features   (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (6, 6)\t1.0\n",
      "  (7, 7)\t1.0\n",
      "  (8, 8)\t1.0\n",
      "  (9, 9)\t1.0\n",
      "  (10, 10)\t1.0\n",
      "  (11, 11)\t1.0\n",
      "  (12, 12)\t1.0\n",
      "  (13, 13)\t1.0\n",
      "  (14, 14)\t1.0\n",
      "  (15, 15)\t1.0\n",
      "  (16, 16)\t1.0\n",
      "  (17, 17)\t1.0\n",
      "  (18, 18)\t1.0\n",
      "  (19, 19)\t1.0\n",
      "  (20, 20)\t1.0\n",
      "  (21, 21)\t1.0\n",
      "  (22, 22)\t1.0\n",
      "  (23, 23)\t1.0\n",
      "  (24, 24)\t1.0\n",
      "  :\t:\n",
      "  (1657, 1657)\t1.0\n",
      "  (1658, 1658)\t1.0\n",
      "  (1659, 1659)\t1.0\n",
      "  (1660, 1660)\t1.0\n",
      "  (1661, 1661)\t1.0\n",
      "  (1662, 1662)\t1.0\n",
      "  (1663, 1663)\t1.0\n",
      "  (1664, 1664)\t1.0\n",
      "  (1665, 1665)\t1.0\n",
      "  (1666, 1666)\t1.0\n",
      "  (1667, 1667)\t1.0\n",
      "  (1668, 1668)\t1.0\n",
      "  (1669, 1669)\t1.0\n",
      "  (1670, 1670)\t1.0\n",
      "  (1671, 1671)\t1.0\n",
      "  (1672, 1672)\t1.0\n",
      "  (1673, 1673)\t1.0\n",
      "  (1674, 1674)\t1.0\n",
      "  (1675, 1675)\t1.0\n",
      "  (1676, 1676)\t1.0\n",
      "  (1677, 1677)\t1.0\n",
      "  (1678, 1678)\t1.0\n",
      "  (1679, 1679)\t1.0\n",
      "  (1680, 1680)\t1.0\n",
      "  (1681, 1681)\t1.0\n"
     ]
    }
   ],
   "source": [
    "#print movie lens \n",
    "for key, value in movielens.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train = movielens['train']\n",
    "test = movielens['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BPR Model\n",
    "\n",
    "We’ll use two metrics of accuracy: precision@k and ROC AUC\n",
    "\n",
    "Both are ranking metrics: to compute them, we’ll be constructing recommendation lists for all of our users, and checking the ranking of known positive movies. \n",
    "\n",
    "For precision at k we’ll be looking at whether they are within the first k results on the list; for AUC, we’ll be calculating the probability that any known positive is higher on the list than a random negative example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(learning_rate=0.05, loss='bpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x10a370278>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.42, test 0.06.\n",
      "AUC: train 0.84, test 0.82.\n"
     ]
    }
   ],
   "source": [
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WARP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = LightFM(learning_rate=0.05, loss='warp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x10a370518>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_partial(train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.60, test 0.11.\n",
      "AUC: train 0.93, test 0.90.\n"
     ]
    }
   ],
   "source": [
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the model output, what do you think?\n",
    "2. Which model do you think will run faster? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype Rec Sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Let's quickly prototype a movie recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm.evaluation import precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 19048 stored elements in COOrdinate format>\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 2153 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "data = fetch_movielens(min_rating=5.0)\n",
    "print(repr(data['train']))\n",
    "print(repr(data['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 627 ms, sys: 7.69 ms, total: 635 ms\n",
      "Wall time: 751 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x10a370400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp')\n",
    "%time model.fit(data['train'], epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision: 0.40\n",
      "Test precision: 0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"Train precision: %.2f\" % precision_at_k(model, data['train'], k=5).mean())\n",
    "print(\"Test precision: %.2f\" % precision_at_k(model, data['test'], k=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample a couple of users and get their recommendations. \n",
    "\n",
    "To make predictions for given user, we pass the id of that user and the ids of all products we want predictions for into the predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sample_recommendation(model, data, user_ids):\n",
    "    \n",
    "    n_users, n_items = data['train'].shape\n",
    "    for user_id in user_ids:\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "        \n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "        \n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "        \n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "        print(\"     Recommended:\")\n",
    "        \n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "     Known positives:\n",
      "        Contact (1997)\n",
      "        Air Force One (1997)\n",
      "        In & Out (1997)\n",
      "     Recommended:\n",
      "        Kiss the Girls (1997)\n",
      "        G.I. Jane (1997)\n",
      "        Lost Highway (1997)\n",
      "User 25\n",
      "     Known positives:\n",
      "        Fargo (1996)\n",
      "        Godfather, The (1972)\n",
      "        L.A. Confidential (1997)\n",
      "     Recommended:\n",
      "        Fargo (1996)\n",
      "        L.A. Confidential (1997)\n",
      "        Star Wars (1977)\n",
      "User 450\n",
      "     Known positives:\n",
      "        Event Horizon (1997)\n",
      "        Scream (1996)\n",
      "        Conspiracy Theory (1997)\n",
      "     Recommended:\n",
      "        Scream (1996)\n",
      "        Game, The (1997)\n",
      "        Air Force One (1997)\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(model, data, [3, 25, 450]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- http://lyst.github.io/lightfm/docs/examples/movielens_implicit.html\n",
    "- http://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
